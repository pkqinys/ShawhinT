{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e691f1-e5d5-4aa4-a53e-6ddcdd23e18d",
   "metadata": {},
   "source": [
    "# Exploring Llama 3.2-Vision (locally) with Ollama\n",
    "\n",
    "Code authored by: Shaw Talebi\n",
    "\n",
    "[Blog link](https://towardsdatascience.com/multimodal-models-llms-that-can-see-and-hear-5c6737c981d3)\n",
    "<br>\n",
    "[Video link](https://youtu.be/Ot2c5MKN_-w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ollama\n",
      "  Using cached ollama-0.5.4-py3-none-any.whl (13 kB)\n",
      "Collecting httpx>=0.27\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Collecting pydantic>=2.9\n",
      "  Using cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Collecting idna\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 2.9 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting anyio\n",
      "  Using cached anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "\u001b[K     |████████████████████████████████| 161 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h11>=0.16\n",
      "  Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting typing-inspection>=0.4.0\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/yisongqin/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9->ollama) (4.15.0)\n",
      "Collecting pydantic-core==2.33.2\n",
      "  Downloading pydantic_core-2.33.2-cp39-cp39-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 30.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/yisongqin/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27->ollama) (1.3.0)\n",
      "Collecting sniffio>=1.1\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: sniffio, idna, h11, certifi, typing-inspection, pydantic-core, httpcore, anyio, annotated-types, pydantic, httpx, ollama\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.10.0 certifi-2025.8.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 ollama-0.5.4 pydantic-2.11.9 pydantic-core-2.33.2 sniffio-1.3.1 typing-inspection-0.4.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004ada7-b590-45ae-87d8-6968558bd932",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "353a71c8-f7c8-4e7d-93df-d3a55cd6b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'llama3.2-vision' # 7b\n",
    "model = 'gemma3:4b' # 4b\n",
    "# model = 'moondream:1.8b' # 1.7b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b99af-7ca5-4628-9377-ddd0f5bf30c7",
   "metadata": {},
   "source": [
    "### pull model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "726a200d-921e-4a8e-a38b-4ac38a99ad25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgressResponse(status='success', completed=None, total=None, digest=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.pull(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c77b5ab-7cd6-4815-b12c-6f7c58dbb5aa",
   "metadata": {},
   "source": [
    "#### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f526327-a9b5-46a9-9008-e9cb65ed260d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The image features a man sitting on a yellow stool or ottoman, wearing a black shirt and tan pants. He has his hands clasped together while smiling at the camera. The room appears to be a living space with various furniture items such as chairs, a couch, and a TV mounted on the wall in the background.\n",
      "\n",
      "There are also several potted plants placed around the room, adding greenery and life to the space. A chair can be seen near one of the potted plants, while another is located closer to the foreground. The man's position on the yellow stool or ottoman suggests that he might be in a casual setting where seating options are provided for guests or family members.\n",
      "\n",
      "Additionally, there is a keyboard placed nearby, possibly indicating that this living space could also serve as a workspace or an area for creative pursuits such as music production or writing.\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(\n",
    "    model=model,\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'What is in this image?',\n",
    "        'images': ['images/shaw-sitting.jpeg']\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfabe75-b6e2-41f4-8538-371192135ae2",
   "metadata": {},
   "source": [
    "#### Image captioning - streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc29b737-6f86-4cee-a7c4-274ba2f10c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urns, plants, and a television are arranged on the wooden floor of a modern living room.\n"
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model=model,\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'Can you write a caption for this image?',\n",
    "        'images': ['images/shaw-sitting.jpeg']\n",
    "    }],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d3738-a3c0-4d44-83b8-7f90ddce9cd6",
   "metadata": {},
   "source": [
    "#### Explaining memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1ac5d88-6438-4ff6-849b-a888c90d8790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The image features a cartoon character, likely Spongebob Squarepants, sitting on a bench in a sandy area. The character is holding a hammer and appears to be working on something or fixing an object nearby. Various objects are scattered around the scene, including a blue wrench, a yellow toolbox, and several other tools. A text overlay at the bottom of the image reads \"Trying to build with AI today....\""
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model=model,\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'Can you explain this meme to me?',\n",
    "        'images': ['images/ai-meme.jpeg']\n",
    "    }],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73926c2f-826f-4a15-8a67-b5ca4e4b6d9e",
   "metadata": {},
   "source": [
    "#### OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06e911d1-533d-48ba-923a-549544aba5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the text from the screenshot formatted in markdown:\n",
      "\n",
      "**5 AI Projects You Can Build This Weekend (with Python)**\n",
      "\n",
      "1.  Resume Optimization (Beginner)\n",
      "    *   Idea: build a tool that adapts your resume for a specific job description\n",
      "\n",
      "2.  YouTube Lecture Summarizer (Beginner)\n",
      "    *   Idea: build a tool that takes YouTube video link and summarizes it\n",
      "\n",
      "3.  Automatically Organizing PDFs (Intermediate)\n",
      "    *   Idea: build a tool to analyze the contents of each PDF and organize them into folders based on topics.\n",
      "\n",
      "4.  Multimodal Search (Intermediate)\n",
      "    *   Idea: Use multimodal embeddings to represent user queries, text knowledge, and images in single space\n",
      "\n",
      "5.  Desktop QA (Advanced)\n",
      "    *   Idea: Connect a multimodal knowledge base to a multimodal model like Llama-3.2-11B-Vision."
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "    model=model,\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'Can you transcribe the text from this screenshot in a markdown format?',\n",
    "        'images': ['images/5-ai-projects.jpeg']\n",
    "    }],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
